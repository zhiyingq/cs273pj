{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# the mock-0.3.1 dir contains testcase.py, testutils.py & mock.py\n",
    "import numpy as np\n",
    "from data_loader_df import *\n",
    "import pandas as pd\n",
    "from sklearn import svm, linear_model, metrics, neural_network, ensemble\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = \"../data/adult.data\"\n",
    "test_file_path = \"../data/adult.test\"\n",
    "\n",
    "train, val, test = load_all_data(train_file_path, test_file_path, valid_rate=0.1, is_df=True, norm=True, one_hot=True)\n",
    "train_X, train_Y, val_X, val_Y, test_X, test_Y = load_all_data(train_file_path, test_file_path, valid_rate=0.1, is_df=False, norm=True, one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "COLUMNS = [\n",
    "\t\t\"age\", \"work\", \"fnlwgt\", \"edu\", \"edunum\",\n",
    "\t\t\"mstatus\", \"occ\", \"relation\", \"race\", \"sex\",\n",
    "\t\t\"cgain\", \"closs\", \"hpw\", \"nation\", \"income\"\n",
    "]\n",
    "COLS_TO_NORM = ['age', 'fnlwgt', 'edunum', 'cgain', 'closs', 'hpw']\n",
    "CATEGORICAL_COLS = [\n",
    "\t\t\"work\", \"edu\", \"mstatus\", \"occ\", \"relation\", \"race\", \"sex\", \"nation\"\n",
    "\t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"----mean & std of features of training data----\")\n",
    "print(np.mean(train[COLS_TO_NORM]))\n",
    "print(np.var(train[COLS_TO_NORM]))\n",
    "print(\"----mean & std of features of validation data----\")\n",
    "print(np.mean(val[COLS_TO_NORM]))\n",
    "print(np.var(val[COLS_TO_NORM]))\n",
    "print(\"----mean & std of features of testing data----\")\n",
    "print(np.mean(test[COLS_TO_NORM]))\n",
    "print(np.var(test[COLS_TO_NORM]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def auc(X, Y, reg):\n",
    "    Y_hat = reg.predict(X);\n",
    "    fpr, tpr, _ = metrics.roc_curve(Y, Y_hat)\n",
    "    return metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matshow(X, Y, X_label, Y_label, train_auc, val_auc, test_auc):\n",
    "    f, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "    cax = ax.matshow(train_auc, interpolation='nearest') \n",
    "    f.colorbar(cax, fraction=0.01, pad=0.04)\n",
    "    ax.set_xticks(np.arange(len(X)))\n",
    "    ax.set_xticklabels(list(X)); ax.set_yticklabels(['']+list(Y))\n",
    "    ax.set_title(\"matshow of train auc\", pad=20)\n",
    "    ax.set_xlabel(X_label)\n",
    "    ax.set_ylabel(Y_label)\n",
    "    plt.show()\n",
    "    \n",
    "    f, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "    cax = ax.matshow(val_auc, interpolation='nearest') \n",
    "    f.colorbar(cax, fraction=0.01, pad=0.04)\n",
    "    ax.set_xticks(np.arange(len(X)))\n",
    "    ax.set_xticklabels(list(X)); ax.set_yticklabels(['']+list(Y))\n",
    "    ax.set_title(\"matshow of val auc\", pad=20)\n",
    "    ax.set_xlabel(X_label)\n",
    "    ax.set_ylabel(Y_label)\n",
    "    plt.show()\n",
    "    \n",
    "    f, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "    cax = ax.matshow(test_auc, interpolation='nearest') \n",
    "    f.colorbar(cax, fraction=0.01, pad=0.04)\n",
    "    ax.set_xticks(np.arange(len(X)))\n",
    "    ax.set_xticklabels(list(X)); ax.set_yticklabels(['']+list(Y))\n",
    "    ax.set_title(\"matshow of test auc\", pad=20)\n",
    "    ax.set_xlabel(X_label)\n",
    "    ax.set_ylabel(Y_label)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = [0.1, 0.2, 0.3, 0.4, 0.5, 0.7, 1, 2, 5, 10, 20, 50]\n",
    "penalties = ['l1', 'l2']\n",
    "\n",
    "auc_train = np.zeros((len(penalties), len(Cs)))\n",
    "auc_val = np.zeros((len(penalties), len(Cs)))\n",
    "auc_test = np.zeros((len(penalties), len(Cs)))\n",
    "\n",
    "for i, penalty in enumerate(penalties):\n",
    "    for j, C in enumerate(Cs):\n",
    "        print(\"processing C =\", C)\n",
    "        reg = linear_model.LogisticRegression(penalty=penalty, C=C)\n",
    "        reg.fit(train_X, train_Y)\n",
    "    \n",
    "        auc_train[i][j] = auc(train_X, train_Y, reg)\n",
    "        auc_val[i][j] = auc(val_X, val_Y, reg)\n",
    "        auc_test[i][j] = auc(test_X, test_Y, reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matshow(Cs, penalties, 'C', 'penalty', auc_train, auc_val, auc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Cs = [0.1, 0.5, 1, 2, 5, 10, 20]\n",
    "kernels = ['rbf', 'linear', 'poly']\n",
    "\n",
    "auc_train = np.zeros((len(kernels), len(Cs)))\n",
    "auc_val = np.zeros((len(kernels), len(Cs)))\n",
    "auc_test = np.zeros((len(kernels), len(Cs)))\n",
    "\n",
    "for i, k in enumerate(kernels):\n",
    "    for j, C in enumerate(Cs):\n",
    "        print(\"processing k=\",k,\", C=\",C);\n",
    "        learner = svm.SVC(C=C, kernel=k, degree=2, gamma='scale');\n",
    "        learner.fit(train_X, train_Y);\n",
    "        auc_train[i][j] = auc(train_X, train_Y, learner)\n",
    "        auc_val[i][j] = auc(val_X, val_Y, learner)\n",
    "        auc_test[i][j] = auc(test_X, test_Y, learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matshow(Cs, kernels, 'C', 'kernel', auc_train, auc_val, auc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layers = range(1, 7, 1)\n",
    "nodes = range(4, 22, 2)\n",
    "auc_train = np.zeros((len(layers), len(nodes)))\n",
    "auc_val = np.zeros((len(layers), len(nodes)))\n",
    "auc_test = np.zeros((len(layers), len(nodes)))\n",
    "\n",
    "for i, layer in enumerate(layers):\n",
    "    for j, node in enumerate(nodes):\n",
    "        print(\"processing layer=\",layer,\", node=\",node)\n",
    "        hidden_layer = tuple([node for k in range(layer)])\n",
    "        learner = neural_network.MLPClassifier(hidden_layer_sizes=hidden_layer, activation='relu', solver='adam')\n",
    "        learner.fit(train_X, train_Y);\n",
    "        \n",
    "        auc_train[i][j] = auc(train_X, train_Y, learner)\n",
    "        auc_val[i][j] = auc(val_X, val_Y, learner)\n",
    "        print(\"test auc: \", auc(test_X, test_Y, learner))\n",
    "        auc_test[i][j] = auc(test_X, test_Y, learner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matshow(nodes, layers, '#nodes', '#layers', auc_train, auc_val, auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "svml = svm.SVC(C=5, kernel='rbf', gamma='scale')\n",
    "nn = neural_network.MLPClassifier(hidden_layer_sizes=(8, 8, 8), activation='relu', solver='adam')\n",
    "# rf = ensemble.RandomForestClassifier(n_estimators=110,max_features=8,min_samples_leaf=10)\n",
    "lc = linear_model.LogisticRegression(penalty='l1', C=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esb = ensemble.VotingClassifier(estimators=[('neural network', nn), \n",
    "                                            ('svm', svml), \n",
    "                                            ('linear classification', lc)], voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esb.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc.fit(train_X, train_Y)\n",
    "svml.fit(train_X, train_Y)\n",
    "nn.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"linear classifer:\")\n",
    "print(visualize_confusion_matrix(test_Y, lc.predict(test_X)))\n",
    "print(\"auc = \", metrics.roc_auc_score(test_Y, lc.predict(test_X)))\n",
    "\n",
    "print(\"svm:\")\n",
    "print(visualize_confusion_matrix(test_Y, svml.predict(test_X)))\n",
    "print(\"auc = \", metrics.roc_auc_score(test_Y, svml.predict(test_X)))\n",
    "\n",
    "print(\"neural network:\")\n",
    "print(visualize_confusion_matrix(test_Y, nn.predict(test_X)))\n",
    "print(\"auc = \", metrics.roc_auc_score(test_Y, nn.predict(test_X)))\n",
    "\n",
    "print(\"ensemble:\")\n",
    "print(visualize_confusion_matrix(test_Y, esb.predict(test_X)))\n",
    "print(\"auc = \", metrics.roc_auc_score(test_Y, esb.predict(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train auc of ensemble: \", auc(train_X, train_Y, esb))\n",
    "print(\"val auc of ensemble: \", auc(val_X, val_Y, esb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest & Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,KFold,GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = \"../data/adult.data\"\n",
    "test_file_path = \"../data/adult.test\"\n",
    "train_X, train_Y, _, _, test_X, test_Y = load_all_data(train_file_path, test_file_path, valid_rate=0, is_df=False, norm=False, one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For trees, we should use label encoding rather than one hot to transfrom category feature\n",
    "#preprocess: combine all the data to do label encoding\n",
    "dataset = np.concatenate((train_X, test_X), axis=0)\n",
    "#trasfrom all features if needed\n",
    "for j in range(14):#14 features in total\n",
    "    if type(dataset[0][j]) == str:\n",
    "        labelencoder = LabelEncoder()\n",
    "        dataset[:, j] = labelencoder.fit_transform(dataset[:, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset back to train, validation, test\n",
    "train_X, test_X = dataset[:30162], dataset[30162:]\n",
    "print(train_X[0])\n",
    "print(test_X[0])\n",
    "print(train_X.shape, test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier(n_estimators=110,max_features=8,min_samples_leaf=10)\n",
    "rf.fit(train_X,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"random forest:\")\n",
    "print(visualize_confusion_matrix(test_Y, rf.predict(test_X)))\n",
    "print(\"auc = \", metrics.roc_auc_score(test_Y, rf.predict(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=44, max_features=8, min_samples_leaf=50)\n",
    "dt.fit(train_X,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"decision tree:\")\n",
    "print(visualize_confusion_matrix(test_Y, dt.predict(test_X)))\n",
    "print(\"auc = \", metrics.roc_auc_score(test_Y, dt.predict(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(test_Y) - sum(test_Y)) / sum(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = pd.DataFrame(lc.coef_, columns=train.drop('income', axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
